/*
    The contents of this file are provided under the terms described in the accompanying License.txt file. Use of this file in any way acknowledges acceptance of these terms.
    Copyright(c) 2010 - 2017, Imagination Technologies Limited and / or its affiliated group companies. All rights reserved.
*/

#define ENABLE_CULLING 1

#define DIRECT_MODE_DISABLED 0
#define DIRECT_MODE_ONLY 1
#define DIRECT_MODE_GI 2

uniform sampler2D  PositionsTex;
uniform sampler2D  InterpolatedNormalsTex;
uniform sampler2D  PlaneNormalsTex;
uniform sampler2D  DirectLighting;
uniform sampler2D  PrevComposite;
uniform sampler2D  ConvergenceMap;
uniform sampler2D  CullingMap;
uniform sampler2D  GISamplesMap;
uniform sampler2D  DirectSamplesMap;
uniform sampler2D  InstanceTransforms;
uniform sampler2D  InstanceProperties;

uniform int InstanceTransformsWidth;
uniform int InstanceTransformsHeight;
uniform int InstancePropertiesWidth;
uniform int InstancePropertiesHeight;
uniform int TransformOffset;
uniform int OutputRayCount;
uniform int DirectSamplesPerPass;
uniform int GISamplesPerPass;
uniform int DirectMaxSamples;
uniform int GIMaxSamples;
uniform float PushOff;
uniform int DirectPassIdx;
uniform int SupersamplingMultiplier;
uniform float OneOverSupersamplingMultiplier;
uniform LightmapMode OutputlightmapMode;
uniform int LODMask;
uniform int LODGroupId;
uniform int DoShadowMask;

void setup()
{
    rl_OutputRayCount = OutputRayCount;
}

mat4 GetInstanceTransform(int instanceIndex, out mat4 inv)
{
    int kPixelsPerInstance = 8;
    int linearIdx = instanceIndex * kPixelsPerInstance;
    int y = int(linearIdx/InstanceTransformsWidth);
    int x = linearIdx - y*InstanceTransformsWidth;
    float xTex = float(x)+0.5;
    float yTex = (float(y)+0.5)/float(InstanceTransformsHeight);
    float w = float(InstanceTransformsWidth);

    vec2 uv1 = vec2(xTex/w, yTex);
    vec2 uv2 = vec2((xTex + 1.0)/w, yTex);
    vec2 uv3 = vec2((xTex + 2.0)/w, yTex);
    vec2 uv4 = vec2((xTex + 3.0)/w, yTex);

    vec4 r1 = texture2D(InstanceTransforms, uv1);
    vec4 r2 = texture2D(InstanceTransforms, uv2);
    vec4 r3 = texture2D(InstanceTransforms, uv3);
    vec4 r4 = texture2D(InstanceTransforms, uv4);

    // load the inverse to transform normals
    float inverse_offset = 4.0 / w;
    vec2 iuv1 = vec2(uv1.x + inverse_offset, uv1.y);
    vec2 iuv2 = vec2(uv2.x + inverse_offset, uv2.y);
    vec2 iuv3 = vec2(uv3.x + inverse_offset, uv3.y);
    vec2 iuv4 = vec2(uv4.x + inverse_offset, uv4.y);

    inv[0] = texture2D(InstanceTransforms, iuv1);
    inv[1] = texture2D(InstanceTransforms, iuv2);
    inv[2] = texture2D(InstanceTransforms, iuv3);
    inv[3] = texture2D(InstanceTransforms, iuv4);

    return mat4(r1,r2,r3,r4);
}

vec4 GetInstanceProperties(int instanceIndex)
{
    int y = int(instanceIndex / InstancePropertiesWidth);
    int x = instanceIndex - y*InstancePropertiesWidth;
    float xTex = (float(x) + 0.5) / float(InstancePropertiesWidth);
    float yTex = (float(y) + 0.5) / float(InstancePropertiesHeight);
    return texture2D(InstanceProperties, vec2(xTex, yTex));
}

bool GetReceiveShadows(vec4 instanceProperties)
{
    // Keep in sync with data generation in PVRContextManager::SetInstanceProperties
    return instanceProperties.x > 0.5;
}

int GetLODGroupId(vec4 instanceProperties)
{
    // Keep in sync with data generation in PVRContextManager::SetInstanceLODData
    return ((instanceProperties.y < 0.0) ? -1 : int(instanceProperties.y));
}

int GetLODMask(vec4 instanceProperties)
{
    // Keep in sync with data generation in PVRContextManager::SetInstanceLODData
    return int(instanceProperties.z);
}

vec2 GetSampleUV (vec2 frameCoord, vec2 frameSize)
{
    int supersamplingMultiplierSquared = SupersamplingMultiplier * SupersamplingMultiplier;
    int sampleIndex = (GetScreenCoordHashMod(frameCoord, supersamplingMultiplierSquared) + DirectPassIdx) % (supersamplingMultiplierSquared);
    int y = int(floor(float(sampleIndex) * OneOverSupersamplingMultiplier));
    int x = sampleIndex - y * SupersamplingMultiplier;

    return (frameCoord - vec2(0.5, 0.5) + (0.5 + vec2(x, y)) * OneOverSupersamplingMultiplier) / frameSize;
}

void GISampling(vec3 position, vec3 planeNormal, vec3 interpNormal, int rayCount, int totalRayCount, LightmapMode lightmapMode)
{
    vec3 b1;
    vec3 b2;

    frisvadONB(interpNormal, b1, b2);

    int scramble = GetScreenCoordHash(rl_FrameCoord.xy);

    // Work out a pseudo random rotation for sample pattern
    int goldenSampleIdx = scramble % IntegratorSamples.numGoldenSamples;
    float rnd = IntegratorSamples.goldenSamples[goldenSampleIdx];
    float rot = rnd * KTWOPI;

    for(int i = 0; i < rayCount; ++i)
    {
        int index = totalRayCount + i;

        vec3 hamDir = GetRotatedHemisphereSample (index, scramble, rnd);

        hamDir = hamDir.x*b1 + hamDir.y*b2 + hamDir.z*interpNormal;

        float dotVal = dot(hamDir, planeNormal);
        if (dotVal <= 0.0 || isnan(dotVal))
            continue;

        createRay();
        rl_OutRay.origin           = position;
        rl_OutRay.direction        = hamDir;
        rl_OutRay.color            = vec4(0.0); // unused, because we're not shooting against lights
        rl_OutRay.probeDir         = normalize(hamDir);
        rl_OutRay.defaultPrimitive = GetEnvPrimitive();
        rl_OutRay.renderTarget     = GI_BUFFER;
        rl_OutRay.isOutgoing       = true;
        rl_OutRay.sampleIndex      = index;
        rl_OutRay.rayClass         = GI_RAY_CLASS;
        rl_OutRay.depth            = 0;
        rl_OutRay.weight           = 1.0;
        rl_OutRay.occlusionTest    = false;
        rl_OutRay.albedo           = vec3(1.0);
        rl_OutRay.sameOriginCount  = 0;
        rl_OutRay.transmissionDepth= 0;
        rl_OutRay.lightmapMode     = lightmapMode;
        rl_OutRay.ignoreDirectEnvironment = false;
        emitRayWithoutDifferentials();
    }

    accumulate(GI_SAMPLES_BUFFER, float(rayCount));
}

void DirectSampling(vec3 position, vec3 normal, int rayCount, int totalRayCount, LightmapMode lightmapMode, bool receiveShadows)
{
    int pixOffset = totalRayCount + GetScreenCoordHashMod(rl_FrameCoord.xy, IntegratorSamples.numGoldenSamples);

    for(int i = 0; i < rayCount; ++i)
    {
        int index = (pixOffset + i) % IntegratorSamples.numGoldenSamples;
        DoShadows(position, normal, vec3(1.0), GI_DIRECT_BUFFER, index, vec3(0.0), lightmapMode, false, OCCLUSIONMODE_DIRECT, vec4(-1.0), 1.0, receiveShadows);
    }

    accumulate(GI_DIRECT_BUFFER, vec4(0.0, 0.0, 0.0, rayCount));
    accumulate(DIRECT_SAMPLES_BUFFER, float(rayCount));
}

void ShadowMaskSampling(vec3 position, vec3 normal, int rayCount, int totalRayCount, bool receiveShadows)
{
    int pixOffset = totalRayCount + GetScreenCoordHashMod(rl_FrameCoord.xy, IntegratorSamples.numGoldenSamples);

    for (int i = 0; i < rayCount; ++i)
    {
        int index = (pixOffset + i) % IntegratorSamples.numGoldenSamples;
        DoShadows(position, normal, vec3(1.0), SHADOW_MASK_BUFFER, index, vec3(0.0), LIGHTMAPMODE_NOTUSED, false, OCCLUSIONMODE_SHADOWMASK, vec4(-1.0), 1.0, receiveShadows);
    }
}

void main()
{
    vec2  frameCoord  = rl_FrameCoord.xy / rl_FrameSize.xy;
    vec2 gbufferUV = GetSampleUV (rl_FrameCoord.xy, rl_FrameSize.xy);

    #if ENABLE_CULLING
    vec4 cull = texture2D(CullingMap, frameCoord);
    if(cull.r <= 0.0)
        return;
    #endif

    int curGISamples = int(texture2D(GISamplesMap, frameCoord).x);
    int curDirectSamples = int(texture2D(DirectSamplesMap, frameCoord).x);

    vec4 conv = texture2D(ConvergenceMap, frameCoord);
    // Check against midpoints between values defined in the convergence job.
    bool isDirectConverged = (conv.r > 32.0/255.0 && conv.r < 96.0/255.0 || conv.r > 160.0/255.0) || curDirectSamples >= DirectMaxSamples;
    bool isGIConverged = conv.r > 96.0/255.0 || curGISamples >= GIMaxSamples;

    vec4 interpObjNormal = texture2D(InterpolatedNormalsTex, gbufferUV);
    vec4 planeObjNormal = texture2D(PlaneNormalsTex, gbufferUV);

    if(interpObjNormal.w < 0.0)
        return;

    vec4 objPosition = texture2D(PositionsTex, gbufferUV);

    int iidx = int(floor(objPosition.w)) + TransformOffset;
    vec4 instanceProperties = GetInstanceProperties(iidx);

    int lodMask = GetLODMask(instanceProperties);
    int lodGroupId = GetLODGroupId(instanceProperties);

    if ((LODGroupId != lodGroupId) || (LODMask != lodMask))
        return;

    mat4 transform_inverse;
    mat4 transform = GetInstanceTransform(iidx, transform_inverse);

    vec3 interpNormal = normalize(mat3(transform_inverse) * interpObjNormal.xyz); // have to multiply with the transposed inverse, so invert multiplication order
    vec3 planeNormal = normalize(mat3(transform_inverse) * planeObjNormal.xyz); // have to multiply with the transposed inverse, so invert multiplication order

    vec4 worldPosition = vec4(objPosition.xyz, 1.0) * transform;
    vec3 position = worldPosition.xyz + planeNormal * PushOff;

    // Avoid overshooting GI samples
    int clampedGIsamplesPerPass = min (max(0, GIMaxSamples - curGISamples), GISamplesPerPass);

    if (!isGIConverged)
        GISampling(position, planeNormal, interpNormal, clampedGIsamplesPerPass, curGISamples, OutputlightmapMode);

    // Avoid overshooting direct samples
    int clampedDirectsamplesPerPass = min (max(0, DirectMaxSamples - curDirectSamples), DirectSamplesPerPass);

    if (!isDirectConverged)
    {
        bool receiveShadows = GetReceiveShadows(instanceProperties);

        // Avoid overshooting direct samples
        int clampedDirectsamplesPerPass = min(max(0, DirectMaxSamples - curDirectSamples), DirectSamplesPerPass);
        DirectSampling(position, interpNormal, clampedDirectsamplesPerPass, curDirectSamples, OutputlightmapMode, receiveShadows);
        if (DoShadowMask == 1)
            ShadowMaskSampling(position, interpNormal, clampedDirectsamplesPerPass, curDirectSamples, receiveShadows);
    }
}
